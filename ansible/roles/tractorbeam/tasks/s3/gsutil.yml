---
- name: Create a temp directory to stage the backup
  tempfile:
    state: directory
    prefix: "s3-{{ _backup.bucket }}-{{ _backup_timestamp }}"
  register: _s3_temp_dir
  when:
    - _backup.cacheDir is not defined
- name: Create a cache directory for the backup
  file:
    state: directory
    path: "{{ _backup.cacheDir }}"
    owner: "backup"
    group: "backup"
    mode: "u=rwx,g=rxw,o=rwx"
  when:
    - _backup.cacheDir is defined
- name: Create the .boto file for the source sync
  copy:
    content: |
      [Credentials]
      aws_access_key_id = {{ _access_key }}
      aws_secret_access_key = {{ _secret_key }}
      {% if _backup.srcEndpoint is defined %}
      s3_host = {{ _backup.srcEndpoint | regex_replace('[A-z]*://', '') }}
      {% endif %}
    dest: "/home/backup/.boto"
    owner: "backup"
    group: "backup"
    mode: "u=rw,g=rw,o="
  vars:
    _access_key: "\
      {% if _backup.srcAccessKeyFile is defined %}\
      {{ lookup('file', _backup.srcAccessKeyFile) }}\
      {% else %}\
      {{ _backup.srcAccessKey | default(omit) }}\
      {% endif %}"
    _secret_key: "\
      {% if _backup.srcSecretKeyFile is defined %}\
      {{ lookup('file', _backup.srcSecretKeyFile) }}\
      {% else %}\
      {{ _backup.srcSecretKey | default(omit) }}\
      {% endif %}"
- name: Sync files from source S3 using gsutil
  shell: >
    gsutil -m rsync
    {% for _exclude in _backup.excludes | default([]) %}
    -x "{{ _exclude }}"{{ '' }}
    {% endfor %}
    {% if _backup.delete | default(true) %}
    -d
    {% endif %}
    -r
    -C
    s3://{{ _backup.srcBucket }}/{% if _backup.prefix is defined %}{{ _backup.prefix }}/{% endif %}
    {{ _backup.cacheDir | default(_s3_temp_dir.path) }}/
  register: _froms3_result
  until: _froms3_result.rc == 0
  retries: "{{ _backup.retryCount | default(3) }}"
  delay: "{{ _backup.retryDelay | default(30) }}"
- name: Create the .boto file for the destination sync
  copy:
    content: |
      [Credentials]
      aws_access_key_id = {{ _access_key }}
      aws_secret_access_key = {{ _secret_key }}
      {% if _backup.endpoint is defined %}
      s3_host = {{ _backup.endpoint | regex_replace('[A-z]*://', '') }}
      {% endif %}
    dest: "/home/backup/.boto"
    owner: "backup"
    group: "backup"
    mode: "u=rw,g=rw,o="
  vars:
    _access_key: "\
      {% if _backup.accessKeyFile is defined %}\
      {{ lookup('file', _backup.accessKeyFile) }}\
      {% else %}\
      {{ _backup.accessKey | default(omit) }}\
      {% endif %}"
    _secret_key: "\
      {% if _backup.secretKeyFile is defined %}\
      {{ lookup('file', _backup.secretKeyFile) }}\
      {% else %}\
      {{ _backup.secretKey | default(omit) }}\
      {% endif %}"
- name: Sync directory to S3 using gsutil
  shell: >
    gsutil -m rsync
    {% for _exclude in _backup.excludes | default([]) %}
    -x "{{ _exclude }}"{{ '' }}
    {% endfor %}
    {% if _backup.delete | default(true) %}
    -d
    {% endif %}
    -r
    -C
    {{ _backup.cacheDir | default(_s3_temp_dir.path) }}/
    s3://{{ _backup.bucket }}/{{ _backup.prefix }}/
  register: _tos3_result
  until: _tos3_result.rc == 0
  retries: "{{ _backup.retryCount | default(3) }}"
  delay: "{{ _backup.retryDelay | default(30) }}"
- name: delete stage directory
  file:
    path: "_s3_temp_dir.path"
    state: absent
  when:
    - _s3_temp_dir.path is defined
- include_tasks: "healhcheck.yml"
